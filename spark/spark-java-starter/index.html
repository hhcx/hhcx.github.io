<!DOCTYPE html><html class="theme-next gemini use-motion" lang="en"><head><meta name="generator" content="Hexo 3.9.0"><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#222"><link rel="stylesheet" href="/lib/needsharebutton/needsharebutton.css"><link rel="stylesheet" href="//fonts.googleapis.com/css?family=Monda:300,300italic,400,400italic,700,700italic|Roboto Slab:300,300italic,400,400italic,700,700italic|PingFang SC:300,300italic,400,400italic,700,700italic|Lobster Two:300,300italic,400,400italic,700,700italic|PT Mono:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext"><link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2"><link rel="stylesheet" href="/css/main.css?v=7.1.1"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=7.1.1"><link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=7.1.1"><link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=7.1.1"><link rel="mask-icon" href="/images/logo.svg?v=7.1.1" color="#222"><script id="hexo.configurations">var NexT=window.NexT||{},CONFIG={root:"/",scheme:"Gemini",version:"7.1.1",sidebar:{position:"left",display:"post",offset:12,onmobile:!0,dimmer:!1},back2top:!0,back2top_sidebar:!0,fancybox:!1,fastclick:!1,lazyload:!1,tabs:!0,motion:{enable:!0,async:!1,transition:{post_block:"fadeIn",post_header:"slideDownIn",post_body:"slideDownIn",coll_header:"slideLeftIn",sidebar:"slideUpIn"}},algolia:{applicationID:"",apiKey:"",indexName:"",hits:{per_page:10},labels:{input_placeholder:"Search for Posts",hits_empty:"We didn't find any results for the search: ${query}",hits_stats:"${hits} results found in ${time} ms"}}}</script><link rel="amphtml" href="./amp/index.html"><meta name="description" content="在 在 Windows 10 中安装和设置 Spark 开发环境 中，我们在 Windwos 中搭建了 Spark 的单机环境以方便开发调试。本文就是在这套环境的基础上演示如何使用 Spark 的 Java API 进行开发。当然，这只是一个简单的入门案例。"><meta name="keywords" content="spark, java"><meta property="og:type" content="article"><meta property="og:title" content="Spark Java API 入门"><meta property="og:url" content="https://www.mls-tech.info/spark/spark-java-starter/index.html"><meta property="og:site_name" content="Morning Star&#39;s blog"><meta property="og:description" content="在 在 Windows 10 中安装和设置 Spark 开发环境 中，我们在 Windwos 中搭建了 Spark 的单机环境以方便开发调试。本文就是在这套环境的基础上演示如何使用 Spark 的 Java API 进行开发。当然，这只是一个简单的入门案例。"><meta property="og:locale" content="en"><meta property="og:updated_time" content="2021-04-16T07:48:48.086Z"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="Spark Java API 入门"><meta name="twitter:description" content="在 在 Windows 10 中安装和设置 Spark 开发环境 中，我们在 Windwos 中搭建了 Spark 的单机环境以方便开发调试。本文就是在这套环境的基础上演示如何使用 Spark 的 Java API 进行开发。当然，这只是一个简单的入门案例。"><link rel="alternate" href="/atom.xml" title="Morning Star's blog" type="application/atom+xml"><link rel="canonical" href="https://www.mls-tech.info/spark/spark-java-starter/"><script id="page.configurations">CONFIG.page={sidebar:""}</script><title>Spark Java API 入门 | Morning Star's blog</title><script async src="//www.googletagmanager.com/gtag/js?id=UA-141018422-1"></script><script>var host=window.location.hostname;function gtag(){dataLayer.push(arguments)}"localhost"!==host&&(window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","UA-141018422-1"))</script><noscript><style>.sidebar-inner,.use-motion .brand,.use-motion .collection-title,.use-motion .comments,.use-motion .menu-item,.use-motion .motion-element,.use-motion .pagination,.use-motion .post-block,.use-motion .post-body,.use-motion .post-header{opacity:initial}.use-motion .logo,.use-motion .site-subtitle,.use-motion .site-title{opacity:initial;top:initial}.use-motion .logo-line-before i{left:initial}.use-motion .logo-line-after i{right:initial}</style></noscript><script type="text/javascript" src="//cdn.bootcss.com/canvas-nest.js/1.0.0/canvas-nest.min.js"></script><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><script>(adsbygoogle=window.adsbygoogle||[]).push({google_ad_client:"ca-pub-0765167544575057",enable_page_level_ads:!0})</script></head><body itemscope itemtype="http://schema.org/WebPage" lang="en"><div class="container sidebar-position-left page-post-detail"><div class="headband"></div><header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="header-inner"><div class="site-brand-wrapper"><div class="site-meta"><div class="custom-logo-site-title"><a href="/" class="brand" rel="start"><span class="logo-line-before"><i></i></span> <span class="site-title">Morning Star's blog</span> <span class="logo-line-after"><i></i></span></a></div></div><div class="site-nav-toggle"><button aria-label="Toggle navigation bar"><span class="btn-bar"></span> <span class="btn-bar"></span> <span class="btn-bar"></span></button></div></div><nav class="site-nav"><ul id="menu" class="menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i><br>Home</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i><br>Tags</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i><br>Categories</a></li><li class="menu-item menu-item-search"><a href="/search/" rel="section"><i class="menu-item-icon fa fa-fw fa-search"></i><br>Search</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i><br>Archives</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="menu-item-icon fa fa-fw fa-user"></i><br>About</a></li></ul></nav></div></header><main id="main" class="main"><div class="main-inner"><div class="content-wrap"><div id="content" class="content"><div id="posts" class="posts-expand"><article class="post post-type-normal" itemscope itemtype="http://schema.org/Article"><div class="post-block"><link itemprop="mainEntityOfPage" href="https://www.mls-tech.info/spark/spark-java-starter/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="name" content="Morning Star"><meta itemprop="description" content><meta itemprop="image" content="/images/avatar.png"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="Morning Star's blog"></span><header class="post-header"><h2 class="post-title" itemprop="name headline">Spark Java API 入门</h2><div class="post-meta"><span class="post-time"><span class="post-meta-item-icon"><i class="fa fa-calendar-o"></i> </span><span class="post-meta-item-text">Posted on</span> <time title="Created: 2020-12-01 07:57:35" itemprop="dateCreated datePublished" datetime="2020-12-01T07:57:35+08:00">2020-12-01</time> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-calendar-check-o"></i> </span><span class="post-meta-item-text">Edited on</span> <time title="Modified: 2021-04-16 15:48:48" itemprop="dateModified" datetime="2021-04-16T15:48:48+08:00">2021-04-16</time> </span><span class="post-category"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-folder-o"></i> </span><span class="post-meta-item-text">In</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/spark/" itemprop="url" rel="index"><span itemprop="name">Spark</span></a></span> </span><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-eye"></i> Views: <span class="busuanzi-value" id="busuanzi_value_page_pv"></span></span><div class="post-symbolscount"><span class="post-meta-item-icon"><i class="fa fa-file-word-o"></i> </span><span class="post-meta-item-text">Symbols count in article: </span><span title="Symbols count in article">12k</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-clock-o"></i> </span><span class="post-meta-item-text">Reading time &asymp;</span> <span title="Reading time">21 mins.</span></div></div></header><div class="post-body" itemprop="articleBody"><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><ins class="adsbygoogle" style="display:block;text-align:center" data-ad-layout="in-article" data-ad-format="fluid" data-ad-client="ca-pub-0765167544575057" data-ad-slot="7762662182"></ins><script>(adsbygoogle=window.adsbygoogle||[]).push({})</script><p>在 <a href="/spark/spark-setup-on-win10/" title="在 Windows 10 中安装和设置 Spark 开发环境">在 Windows 10 中安装和设置 Spark 开发环境</a> 中，我们在 Windwos 中搭建了 Spark 的单机环境以方便开发调试。本文就是在这套环境的基础上演示如何使用 Spark 的 Java API 进行开发。当然，这只是一个简单的入门案例。</p><a id="more"></a><p>本文参考了 Spark 官方的案例。</p><p>在搭建好 Spark 的环境后， 我们使用如下的软件来进行 Spark 应用的开发:</p><ol><li>JDK： Java 8</li><li>IDE: IDEA Intellij 社区版就可以</li></ol><h2 id="建立一个-maven-项目"><a href="#建立一个-maven-项目" class="headerlink" title="建立一个 maven 项目"></a>建立一个 maven 项目</h2><p>打开 IDEA, 新建一个普通的 maven 项目， 建好以后，打开项目中的 pom.xml 文件，</p><p>首先添加 Spark 依赖库，内容如下:</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span> <span class="comment">&lt;!-- Spark dependency --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.spark<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spark-core_2.11<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.1.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br></pre></td></tr></table></figure><p>因为我们在那里中会使用 Java 8的特性，所以需要添加对 Java 8 的支持，内容如下:</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">build</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">plugins</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">             <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.maven.plugins<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">             <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>maven-compiler-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">             <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.6.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">             <span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">                 <span class="tag">&lt;<span class="name">source</span>&gt;</span>1.8<span class="tag">&lt;/<span class="name">source</span>&gt;</span></span><br><span class="line">                 <span class="tag">&lt;<span class="name">target</span>&gt;</span>1.8<span class="tag">&lt;/<span class="name">target</span>&gt;</span></span><br><span class="line">             <span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;/<span class="name">plugins</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;/<span class="name">build</span>&gt;</span></span><br></pre></td></tr></table></figure><h2 id="编写-Java-类"><a href="#编写-Java-类" class="headerlink" title="编写 Java 类"></a>编写 Java 类</h2><p>在项目中新建一个名为: SimpleApp 的类，该类包含 main 方法，所以可以被直接执行。然后类中编写以下内容:</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.SparkConf;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.api.java.JavaRDD;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.api.java.JavaSparkContext;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.api.java.function.Function;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SimpleApp</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">        String logFile = <span class="string">"file:///d:/Devel/spark-2.4.4-bin-hadoop2.7/README.md"</span>;</span><br><span class="line"></span><br><span class="line">        SparkConf conf = <span class="keyword">new</span> SparkConf().setAppName(<span class="string">"Simple Application"</span>);</span><br><span class="line"></span><br><span class="line">        JavaSparkContext sc = <span class="keyword">new</span> JavaSparkContext(conf);</span><br><span class="line"></span><br><span class="line">        JavaRDD&lt;String&gt; logData = sc.textFile(logFile).cache();</span><br><span class="line"></span><br><span class="line">        <span class="keyword">long</span> numAs = logData.filter(<span class="keyword">new</span> Function&lt;String, Boolean&gt;() &#123;</span><br><span class="line">            <span class="function"><span class="keyword">public</span> Boolean <span class="title">call</span><span class="params">(String s)</span> </span>&#123;</span><br><span class="line">                <span class="keyword">return</span> s.contains(<span class="string">"a"</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;).count();</span><br><span class="line"></span><br><span class="line">        <span class="keyword">long</span> numBs = logData.filter(s -&gt; &#123;</span><br><span class="line">            <span class="keyword">return</span> s.contains(<span class="string">"b"</span>);</span><br><span class="line">        &#125;).count();</span><br><span class="line"></span><br><span class="line">        System.out.println(<span class="string">"Lines with a: "</span> + numAs + <span class="string">", lines with b: "</span> + numBs);</span><br><span class="line"></span><br><span class="line">        sc.stop();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>我们简单的解释以下程序的内容,</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">SparkConf conf = <span class="keyword">new</span> SparkConf().setAppName(<span class="string">"Simple Application"</span>);</span><br><span class="line"></span><br><span class="line">JavaSparkContext sc = <span class="keyword">new</span> JavaSparkContext(conf);</span><br></pre></td></tr></table></figure><p>这两句代码是为了构建一个 SparkContext, 在上面代码给定的 SparkConf 条件中， JavaSparkContext 会自动通过当前环境中的环境变量 SPARK_HOME 找到需要的 Spark 安装包并启动一个 Spark 运行实例。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">JavaRDD&lt;String&gt; logData = sc.textFile(logFile).cache();</span><br></pre></td></tr></table></figure><p>这行代码声明了一个弹性数据集，内容来自于 logFile。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">long</span> numAs = logData.filter(<span class="keyword">new</span> Function&lt;String, Boolean&gt;() &#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> Boolean <span class="title">call</span><span class="params">(String s)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> s.contains(<span class="string">"a"</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;).count();</span><br></pre></td></tr></table></figure><p>这几行代码基于弹性数据集进行了一个简单的运算，首先是一个 filter 操作，该操作需要根据特定的筛选条件对数据进行筛选，而这个特定的筛选条件被封装到了接口 Function 中。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">long</span> numBs = logData.filter(s -&gt; &#123;</span><br><span class="line">    <span class="keyword">return</span> s.contains(<span class="string">"b"</span>);</span><br><span class="line">&#125;).count();</span><br></pre></td></tr></table></figure><p>这几行代码使用了 Java 8 中的 Lambda 表达式简化了代码，功能和计算 numAs 的代码是一样的。</p><h2 id="运行程序"><a href="#运行程序" class="headerlink" title="运行程序"></a>运行程序</h2><p>在 IDEA 中选择运行，会弹出配置对话框，在对话框中选择 SimpleApp 作为启动程序， 然后<strong>在 VM options 选择中填入: -Dspark.master=local 以指名启用本地安装的 Spark</strong></p><p>配置好后，就可以运行程序， 如果运行正常，会得到类似如下的结果（输出）:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br></pre></td><td class="code"><pre><span class="line">Using Spark<span class="string">'s default log4j profile: org/apache/spark/log4j-defaults.properties</span></span><br><span class="line"><span class="string">20/12/01 07:52:42 INFO SparkContext: Running Spark version 2.1.0</span></span><br><span class="line"><span class="string">20/12/01 07:52:43 INFO SecurityManager: Changing view acls to: stu</span></span><br><span class="line"><span class="string">20/12/01 07:52:43 INFO SecurityManager: Changing modify acls to: stu</span></span><br><span class="line"><span class="string">20/12/01 07:52:43 INFO SecurityManager: Changing view acls groups to: </span></span><br><span class="line"><span class="string">20/12/01 07:52:43 INFO SecurityManager: Changing modify acls groups to: </span></span><br><span class="line"><span class="string">20/12/01 07:52:43 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(stu); groups with view permissions: Set(); users  with modify permissions: Set(stu); groups with modify permissions: Set()</span></span><br><span class="line"><span class="string">20/12/01 07:52:45 INFO Utils: Successfully started service '</span>sparkDriver<span class="string">' on port 65032.</span></span><br><span class="line"><span class="string">20/12/01 07:52:45 INFO SparkEnv: Registering MapOutputTracker</span></span><br><span class="line"><span class="string">20/12/01 07:52:45 INFO SparkEnv: Registering BlockManagerMaster</span></span><br><span class="line"><span class="string">20/12/01 07:52:45 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information</span></span><br><span class="line"><span class="string">20/12/01 07:52:45 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up</span></span><br><span class="line"><span class="string">20/12/01 07:52:45 INFO DiskBlockManager: Created local directory at C:\Users\stu\AppData\Local\Temp\blockmgr-b4f340e4-2ff9-48dd-ba8f-2b7b44f2e2f4</span></span><br><span class="line"><span class="string">20/12/01 07:52:45 INFO MemoryStore: MemoryStore started with capacity 871.8 MB</span></span><br><span class="line"><span class="string">20/12/01 07:52:45 INFO SparkEnv: Registering OutputCommitCoordinator</span></span><br><span class="line"><span class="string">20/12/01 07:52:45 INFO Utils: Successfully started service '</span>SparkUI<span class="string">' on port 4040.</span></span><br><span class="line"><span class="string">20/12/01 07:52:45 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://192.168.3.73:4040</span></span><br><span class="line"><span class="string">20/12/01 07:52:46 INFO Executor: Starting executor ID driver on host localhost</span></span><br><span class="line"><span class="string">20/12/01 07:52:46 INFO Utils: Successfully started service '</span>org.apache.spark.network.netty.NettyBlockTransferService<span class="string">' on port 65046.</span></span><br><span class="line"><span class="string">20/12/01 07:52:46 INFO NettyBlockTransferService: Server created on 192.168.3.73:65046</span></span><br><span class="line"><span class="string">20/12/01 07:52:46 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy</span></span><br><span class="line"><span class="string">20/12/01 07:52:46 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.3.73, 65046, None)</span></span><br><span class="line"><span class="string">20/12/01 07:52:46 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.3.73:65046 with 871.8 MB RAM, BlockManagerId(driver, 192.168.3.73, 65046, None)</span></span><br><span class="line"><span class="string">20/12/01 07:52:46 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 192.168.3.73, 65046, None)</span></span><br><span class="line"><span class="string">20/12/01 07:52:46 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 192.168.3.73, 65046, None)</span></span><br><span class="line"><span class="string">20/12/01 07:52:47 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 127.1 KB, free 871.7 MB)</span></span><br><span class="line"><span class="string">20/12/01 07:52:47 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.3 KB, free 871.7 MB)</span></span><br><span class="line"><span class="string">20/12/01 07:52:47 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 192.168.3.73:65046 (size: 14.3 KB, free: 871.8 MB)</span></span><br><span class="line"><span class="string">20/12/01 07:52:47 INFO SparkContext: Created broadcast 0 from textFile at SimpleApp.java:18</span></span><br><span class="line"><span class="string">20/12/01 07:52:47 INFO FileInputFormat: Total input paths to process : 1</span></span><br><span class="line"><span class="string">20/12/01 07:52:47 INFO SparkContext: Starting job: count at SimpleApp.java:24</span></span><br><span class="line"><span class="string">20/12/01 07:52:47 INFO DAGScheduler: Got job 0 (count at SimpleApp.java:24) with 1 output partitions</span></span><br><span class="line"><span class="string">20/12/01 07:52:47 INFO DAGScheduler: Final stage: ResultStage 0 (count at SimpleApp.java:24)</span></span><br><span class="line"><span class="string">20/12/01 07:52:47 INFO DAGScheduler: Parents of final stage: List()</span></span><br><span class="line"><span class="string">20/12/01 07:52:47 INFO DAGScheduler: Missing parents: List()</span></span><br><span class="line"><span class="string">20/12/01 07:52:47 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[2] at filter at SimpleApp.java:20), which has no missing parents</span></span><br><span class="line"><span class="string">20/12/01 07:52:47 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 3.4 KB, free 871.7 MB)</span></span><br><span class="line"><span class="string">20/12/01 07:52:47 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.0 KB, free 871.7 MB)</span></span><br><span class="line"><span class="string">20/12/01 07:52:47 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 192.168.3.73:65046 (size: 2.0 KB, free: 871.8 MB)</span></span><br><span class="line"><span class="string">20/12/01 07:52:47 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:996</span></span><br><span class="line"><span class="string">20/12/01 07:52:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at filter at SimpleApp.java:20)</span></span><br><span class="line"><span class="string">20/12/01 07:52:47 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks</span></span><br><span class="line"><span class="string">20/12/01 07:52:47 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 5914 bytes)</span></span><br><span class="line"><span class="string">20/12/01 07:52:47 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)</span></span><br><span class="line"><span class="string">20/12/01 07:52:48 INFO HadoopRDD: Input split: file:/c:/Devel/spark-2.4.4-bin-hadoop2.7/README.md:0+3952</span></span><br><span class="line"><span class="string">20/12/01 07:52:48 INFO deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id</span></span><br><span class="line"><span class="string">20/12/01 07:52:48 INFO deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id</span></span><br><span class="line"><span class="string">20/12/01 07:52:48 INFO deprecation: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap</span></span><br><span class="line"><span class="string">20/12/01 07:52:48 INFO deprecation: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition</span></span><br><span class="line"><span class="string">20/12/01 07:52:48 INFO deprecation: mapred.job.id is deprecated. Instead, use mapreduce.job.id</span></span><br><span class="line"><span class="string">20/12/01 07:52:48 INFO MemoryStore: Block rdd_1_0 stored as values in memory (estimated size 11.6 KB, free 871.6 MB)</span></span><br><span class="line"><span class="string">20/12/01 07:52:48 INFO BlockManagerInfo: Added rdd_1_0 in memory on 192.168.3.73:65046 (size: 11.6 KB, free: 871.8 MB)</span></span><br><span class="line"><span class="string">20/12/01 07:52:48 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 2005 bytes result sent to driver</span></span><br><span class="line"><span class="string">20/12/01 07:52:48 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 362 ms on localhost (executor driver) (1/1)</span></span><br><span class="line"><span class="string">20/12/01 07:52:48 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool </span></span><br><span class="line"><span class="string">20/12/01 07:52:48 INFO DAGScheduler: ResultStage 0 (count at SimpleApp.java:24) finished in 0.395 s</span></span><br><span class="line"><span class="string">20/12/01 07:52:48 INFO DAGScheduler: Job 0 finished: count at SimpleApp.java:24, took 0.559096 s</span></span><br><span class="line"><span class="string">20/12/01 07:52:48 INFO SparkContext: Starting job: count at SimpleApp.java:30</span></span><br><span class="line"><span class="string">20/12/01 07:52:48 INFO DAGScheduler: Got job 1 (count at SimpleApp.java:30) with 1 output partitions</span></span><br><span class="line"><span class="string">20/12/01 07:52:48 INFO DAGScheduler: Final stage: ResultStage 1 (count at SimpleApp.java:30)</span></span><br><span class="line"><span class="string">20/12/01 07:52:48 INFO DAGScheduler: Parents of final stage: List()</span></span><br><span class="line"><span class="string">20/12/01 07:52:48 INFO DAGScheduler: Missing parents: List()</span></span><br><span class="line"><span class="string">20/12/01 07:52:48 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[3] at filter at SimpleApp.java:26), which has no missing parents</span></span><br><span class="line"><span class="string">20/12/01 07:52:48 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 3.4 KB, free 871.6 MB)</span></span><br><span class="line"><span class="string">20/12/01 07:52:48 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.0 KB, free 871.6 MB)</span></span><br><span class="line"><span class="string">20/12/01 07:52:48 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 192.168.3.73:65046 (size: 2.0 KB, free: 871.8 MB)</span></span><br><span class="line"><span class="string">20/12/01 07:52:48 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:996</span></span><br><span class="line"><span class="string">20/12/01 07:52:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[3] at filter at SimpleApp.java:26)</span></span><br><span class="line"><span class="string">20/12/01 07:52:48 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks</span></span><br><span class="line"><span class="string">20/12/01 07:52:48 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 5914 bytes)</span></span><br><span class="line"><span class="string">20/12/01 07:52:48 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)</span></span><br><span class="line"><span class="string">20/12/01 07:52:48 INFO BlockManager: Found block rdd_1_0 locally</span></span><br><span class="line"><span class="string">20/12/01 07:52:48 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1131 bytes result sent to driver</span></span><br><span class="line"><span class="string">20/12/01 07:52:48 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 17 ms on localhost (executor driver) (1/1)</span></span><br><span class="line"><span class="string">20/12/01 07:52:48 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool </span></span><br><span class="line"><span class="string">20/12/01 07:52:48 INFO DAGScheduler: ResultStage 1 (count at SimpleApp.java:30) finished in 0.019 s</span></span><br><span class="line"><span class="string">20/12/01 07:52:48 INFO DAGScheduler: Job 1 finished: count at SimpleApp.java:30, took 0.039857 s</span></span><br><span class="line"><span class="string">20/12/01 07:52:48 INFO SparkContext: Starting job: count at SimpleApp.java:34</span></span><br><span class="line"><span class="string">20/12/01 07:52:48 INFO DAGScheduler: Got job 2 (count at SimpleApp.java:34) with 1 output partitions</span></span><br><span class="line"><span class="string">20/12/01 07:52:48 INFO DAGScheduler: Final stage: ResultStage 2 (count at SimpleApp.java:34)</span></span><br><span class="line"><span class="string">20/12/01 07:52:48 INFO DAGScheduler: Parents of final stage: List()</span></span><br><span class="line"><span class="string">20/12/01 07:52:48 INFO DAGScheduler: Missing parents: List()</span></span><br><span class="line"><span class="string">20/12/01 07:52:48 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[4] at filter at SimpleApp.java:32), which has no missing parents</span></span><br><span class="line"><span class="string">20/12/01 07:52:48 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 4.0 KB, free 871.6 MB)</span></span><br><span class="line"><span class="string">20/12/01 07:52:48 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 2.3 KB, free 871.6 MB)</span></span><br><span class="line"><span class="string">20/12/01 07:52:48 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 192.168.3.73:65046 (size: 2.3 KB, free: 871.8 MB)</span></span><br><span class="line"><span class="string">20/12/01 07:52:48 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:996</span></span><br><span class="line"><span class="string">20/12/01 07:52:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[4] at filter at SimpleApp.java:32)</span></span><br><span class="line"><span class="string">20/12/01 07:52:48 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks</span></span><br><span class="line"><span class="string">20/12/01 07:52:48 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 5914 bytes)</span></span><br><span class="line"><span class="string">20/12/01 07:52:48 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)</span></span><br><span class="line"><span class="string">20/12/01 07:52:48 INFO BlockManager: Found block rdd_1_0 locally</span></span><br><span class="line"><span class="string">20/12/01 07:52:48 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1044 bytes result sent to driver</span></span><br><span class="line"><span class="string">20/12/01 07:52:48 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 20 ms on localhost (executor driver) (1/1)</span></span><br><span class="line"><span class="string">20/12/01 07:52:48 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool </span></span><br><span class="line"><span class="string">20/12/01 07:52:48 INFO DAGScheduler: ResultStage 2 (count at SimpleApp.java:34) finished in 0.022 s</span></span><br><span class="line"><span class="string">20/12/01 07:52:48 INFO DAGScheduler: Job 2 finished: count at SimpleApp.java:34, took 0.035629 s</span></span><br><span class="line"><span class="string">Lines with a: 62, lines with b: 31</span></span><br><span class="line"><span class="string">20/12/01 07:52:48 INFO SparkUI: Stopped Spark web UI at http://192.168.3.73:4040</span></span><br><span class="line"><span class="string">20/12/01 07:52:48 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!</span></span><br><span class="line"><span class="string">20/12/01 07:52:48 INFO MemoryStore: MemoryStore cleared</span></span><br><span class="line"><span class="string">20/12/01 07:52:48 INFO BlockManager: BlockManager stopped</span></span><br><span class="line"><span class="string">20/12/01 07:52:48 INFO BlockManagerMaster: BlockManagerMaster stopped</span></span><br><span class="line"><span class="string">20/12/01 07:52:48 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!</span></span><br><span class="line"><span class="string">20/12/01 07:52:48 INFO SparkContext: Successfully stopped SparkContext</span></span><br><span class="line"><span class="string">20/12/01 07:52:48 INFO ShutdownHookManager: Shutdown hook called</span></span><br><span class="line"><span class="string">20/12/01 07:52:48 INFO ShutdownHookManager: Deleting directory C:\Users\stu\AppData\Local\Temp\spark-0d309824-2a28-4547-b2b8-50df4dae1482</span></span><br></pre></td></tr></table></figure></div><div class="popular-posts-header">Related Articles</div><ul class="popular-posts"><li class="popular-posts-item"><div class="popular-posts-title"><a href="/spark/spark-cluster-on-docker-2/" rel="bookmark">在 Docker 中配置 Spark 集群(二)</a></div></li><li class="popular-posts-item"><div class="popular-posts-title"><a href="/spark/spark-cluster-on-docker-1/" rel="bookmark">在 Docker 中配置 Spark 集群(一)</a></div></li><li class="popular-posts-item"><div class="popular-posts-title"><a href="/spark/spark-setup-on-win10/" rel="bookmark">在 Windows 10 中安装和设置 Spark 开发环境</a></div></li></ul><div><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-0765167544575057" data-ad-slot="9592363579" data-ad-format="auto" data-full-width-responsive="true"></ins><script>(adsbygoogle=window.adsbygoogle||[]).push({})</script><div class="my_post_copyright"><script src="//cdn.bootcss.com/clipboard.js/1.5.10/clipboard.min.js"></script><script src="https://cdn.bootcss.com/jquery/2.0.0/jquery.min.js"></script><script src="https://unpkg.com/sweetalert/dist/sweetalert.min.js"></script><p><span>本文标题:</span><a href="/spark/spark-java-starter/">Spark Java API 入门</a></p><p><span>文章作者:</span><a href="/" title="访问 Morning Star 的个人博客">Morning Star</a></p><p><span>发布时间:</span>2020年12月01日 - 07:12</p><p><span>最后更新:</span>2021年04月16日 - 15:04</p><p><span>原始链接:</span><a href="/spark/spark-java-starter/" title="Spark Java API 入门">https://www.mls-tech.info/spark/spark-java-starter/</a> <span class="copy-path" title="点击复制文章链接"><i class="fa fa-clipboard" data-clipboard-text="https://www.mls-tech.info/spark/spark-java-starter/" aria-label="复制成功！"></i></span></p><p><span>许可协议:</span><i class="fa fa-creative-commons"></i> <a rel="external nofollow noopener noreferrer" href="https://creativecommons.org/licenses/by-nc-nd/4.0/" target="_blank" title="Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0)">署名-非商业性使用-禁止演绎 4.0 国际</a> 转载请保留原文链接及作者。</p></div><script>var clipboard=new Clipboard(".fa-clipboard");$(".fa-clipboard").click(function(){clipboard.on("success",function(){swal({title:"",text:"复制成功",icon:"success",showConfirmButton:!0})})})</script></div><footer class="post-footer"><div class="post-tags"><a href="/tags/spark/" rel="tag"># Spark</a></div><div class="post-widgets"><div class="social_share"><div id="needsharebutton-postbottom"><span class="btn"><i class="fa fa-share-alt" aria-hidden="true"></i></span></div></div></div><div class="post-nav"><div class="post-nav-next post-nav-item"><a href="/spark/spark-cluster-on-docker-2/" rel="next" title="在 Docker 中配置 Spark 集群(二)"><i class="fa fa-chevron-left"></i> 在 Docker 中配置 Spark 集群(二)</a></div><span class="post-nav-divider"></span><div class="post-nav-prev post-nav-item"><a href="/docker/docker-springboot-build-error-1/" rel="prev" title="解决  I/O exception (java.io.IOException) caught when processing request to {}->unix://localhost:80 的错误">解决 I/O exception (java.io.IOException) caught when processing request to {}->unix://localhost:80 的错误 <i class="fa fa-chevron-right"></i></a></div></div></footer></div></article></div></div></div><div class="sidebar-toggle"><div class="sidebar-toggle-line-wrap"><span class="sidebar-toggle-line sidebar-toggle-line-first"></span> <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span> <span class="sidebar-toggle-line sidebar-toggle-line-last"></span></div></div><aside id="sidebar" class="sidebar"><div class="sidebar-inner"><ul class="sidebar-nav motion-element"><li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">Table of Contents</li><li class="sidebar-nav-overview" data-target="site-overview-wrap">Overview</li></ul><div class="site-overview-wrap sidebar-panel"><div class="site-overview"><div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="site-author-image" itemprop="image" src="/images/avatar.png" alt="Morning Star"><p class="site-author-name" itemprop="name">Morning Star</p><div class="site-description motion-element" itemprop="description"></div></div><nav class="site-state motion-element"><div class="site-state-item site-state-posts"><a href="/archives/"><span class="site-state-item-count">580</span> <span class="site-state-item-name">posts</span></a></div><div class="site-state-item site-state-categories"><a href="/categories/"><span class="site-state-item-count">42</span> <span class="site-state-item-name">categories</span></a></div><div class="site-state-item site-state-tags"><a href="/tags/"><span class="site-state-item-count">43</span> <span class="site-state-item-name">tags</span></a></div></nav><div class="feed-link motion-element"><a href="/atom.xml" rel="alternate"><i class="fa fa-rss"></i> RSS</a></div><div class="links-of-author motion-element"><span class="links-of-author-item"><a href="https://github.com/MaxM2013" title="GitHub &rarr; https://github.com/MaxM2013" rel="external nofollow noopener noreferrer" target="_blank"><i class="fa fa-fw fa-fab fa-github"></i></a> </span><span class="links-of-author-item"><a href="mailto:mls-tech@outlook.com" title="E-Mail &rarr; mailto:mls-tech@outlook.com" rel="external nofollow noopener noreferrer" target="_blank"><i class="fa fa-fw fa-fa fa-envelope"></i></a> </span><span class="links-of-author-item"><a href="https://www.facebook.com/Mlstech2013" title="FB Page &rarr; https://www.facebook.com/Mlstech2013" rel="external nofollow noopener noreferrer" target="_blank"><i class="fa fa-fw fa-facebook"></i></a> </span><span class="links-of-author-item"><a href="https://www.youtube.com/channel/UC2PKa97_c2YaDEYsaXN8KNQ" title="YouTube &rarr; https://www.youtube.com/channel/UC2PKa97_c2YaDEYsaXN8KNQ" rel="external nofollow noopener noreferrer" target="_blank"><i class="fa fa-fw fa-youtube"></i></a></span></div><div class="wechat_channel"><br><img src="/images/wechat_channel.png"></div><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-0765167544575057" data-ad-slot="6828020316" data-ad-format="auto" data-full-width-responsive="true"></ins><script>(adsbygoogle=window.adsbygoogle||[]).push({})</script></div></div><div class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active"><div class="post-toc"><div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#建立一个-maven-项目"><span class="nav-number">1.</span> <span class="nav-text">建立一个 maven 项目</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#编写-Java-类"><span class="nav-number">2.</span> <span class="nav-text">编写 Java 类</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#运行程序"><span class="nav-number">3.</span> <span class="nav-text">运行程序</span></a></li></ol></div></div></div><div class="back-to-top"><i class="fa fa-arrow-up"></i></div></div></aside></div></main><footer id="footer" class="footer"><div class="footer-inner"><div class="copyright">&copy; <span itemprop="copyrightYear">2022</span> <span class="with-love" id="animate"><i class="fa fa-user"></i> </span><span class="author" itemprop="copyrightHolder">Morning Star</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-area-chart"></i> </span><span title="Symbols count total">1.1m</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-coffee"></i> </span><span title="Reading time total">31:11</span></div><div class="powered-by">Powered by <a href="https://hexo.io" class="theme-link" rel="external nofollow noopener noreferrer" target="_blank">Hexo</a> v3.9.0</div><span class="post-meta-divider">|</span><div class="theme-info">Theme – <a href="https://theme-next.org" class="theme-link" rel="external nofollow noopener noreferrer" target="_blank">NexT.Gemini</a> v7.1.1</div><div class="busuanzi-count"><script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span class="post-meta-item-icon"><i class="fa fa-user"></i> </span><span class="site-uv" title="Total Visitors"><span class="busuanzi-value" id="busuanzi_value_site_uv"></span> </span><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-eye"></i> </span><span class="site-pv" title="Total Views"><span class="busuanzi-value" id="busuanzi_value_site_pv"></span></span></div></div></footer></div><script>"[object Function]"!==Object.prototype.toString.call(window.Promise)&&(window.Promise=null)</script><script src="/lib/jquery/index.js?v=2.1.3"></script><script src="/lib/velocity/velocity.min.js?v=1.2.1"></script><script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script><script src="/lib/three/three.min.js"></script><script src="/lib/three/three-waves.min.js"></script><script src="/js/utils.js?v=7.1.1"></script><script src="/js/motion.js?v=7.1.1"></script><script src="/js/affix.js?v=7.1.1"></script><script src="/js/schemes/pisces.js?v=7.1.1"></script><script src="/js/scrollspy.js?v=7.1.1"></script><script src="/js/post-details.js?v=7.1.1"></script><script src="/js/next-boot.js?v=7.1.1"></script><script src="/js/js.cookie.js?v=7.1.1"></script><script src="/js/scroll-cookie.js?v=7.1.1"></script><script src="/lib/needsharebutton/needsharebutton.js"></script><script>pbOptions={iconStyle:"box",boxForm:"horizontal",position:"bottomCenter",networks:"Weibo,Wechat,Douban,QQZone,Twitter,Facebook"},new needShareButton("#needsharebutton-postbottom",pbOptions)</script><script>$(".highlight").not(".gist .highlight").each(function(t,e){var n=$("<div>").addClass("highlight-wrap");$(e).after(n),n.append($("<button>").addClass("copy-btn").append("Copy").on("click",function(t){var e=$(this).parent().find(".code").find(".line").map(function(t,e){return $(e).text()}).toArray().join("\n"),n=document.createElement("textarea"),o=window.pageYOffset||document.documentElement.scrollTop;n.style.top=o+"px",n.style.position="absolute",n.style.opacity="0",n.readOnly=!0,n.value=e,document.body.appendChild(n),n.select(),n.setSelectionRange(0,e.length),n.readOnly=!1,document.execCommand("copy")?$(this).text("Copied"):$(this).text("Copy failed"),n.blur(),$(this).blur()})).on("mouseleave",function(t){var e=$(this).find(".copy-btn");setTimeout(function(){e.text("Copy")},300)}).append(e)})</script></body></html>